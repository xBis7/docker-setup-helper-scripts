CORE-SITE.XML_fs.defaultFS=hdfs://namenode:8020

# After enabling trino impersonation, trino communicates with HDFS
# either as 'trino' proxy user or 'hive' proxy user.
# With these properties we are allowing the proxy users to authenticate with HDFS.
CORE-SITE.XML_hadoop.proxyuser.trino.hosts=*
CORE-SITE.XML_hadoop.proxyuser.trino.groups=*
CORE-SITE.XML_hadoop.proxyuser.hive.hosts=*
CORE-SITE.XML_hadoop.proxyuser.hive.groups=*

CORE-SITE.XML_hadoop.proxyuser.hadoop.hosts=*
CORE-SITE.XML_hadoop.proxyuser.hadoop.groups=*

# core-site.xml Kerberos config
CORE-SITE.XML_hadoop.security.authentication=kerberos
CORE-SITE.XML_hadoop.security.authorization=true
CORE-SITE.XML_hadoop.security.krb5.conf=/etc/krb5.conf
CORE-SITE.XML_hadoop.rpc.protection=privacy

# core-site.xml ssl config
CORE-SITE.XML_hadoop.ssl.require.client.cert=false
CORE-SITE.XML_hadoop.ssl.hostname.verifier=DEFAULT
CORE-SITE.XML_hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
CORE-SITE.XML_hadoop.ssl.server.conf=ssl-server.xml
CORE-SITE.XML_hadoop.ssl.client.conf=ssl-client.xml

HDFS-SITE.XML_dfs.namenode.rpc-address=namenode:8020
HDFS-SITE.XML_dfs.replication=1

# Security - Ranger
HDFS-SITE.XML_dfs.permissions.enabled=true
HDFS-SITE.XML_dfs.namenode.acls.enabled=true
HDFS-SITE.XML_dfs.permissions.ContentSummary.subAccess=true
HDFS-SITE.XML_dfs.namenode.inode.attributes.provider.class=org.apache.ranger.authorization.hadoop.RangerHdfsAuthorizer

# hdfs-site.xml Kerberos config
HDFS-SITE.XML_dfs.namenode.kerberos.principal=hadoop/nn@EXAMPLE.COM
HDFS-SITE.XML_dfs.namenode.keytab.file=/etc/security/keytabs/hadoop.nn.keytab    

HDFS-SITE.XML_dfs.datanode.kerberos.principal=hadoop/dn1@EXAMPLE.COM
HDFS-SITE.XML_dfs.datanode.keytab.file=/etc/security/keytabs/hadoop.dn1.keytab

HDFS-SITE.XML_dfs.namenode.kerberos.principal.pattern=*

HDFS-SITE.XML_dfs.block.access.token.enable=true
HDFS-SITE.XML_dfs.data.transfer.protection=integrity
HDFS-SITE.XML_dfs.datanode.address=0.0.0.0:10019
HDFS-SITE.XML_dfs.datanode.http.address=0.0.0.0:10022
HDFS-SITE.XML_dfs.datanode.data.dir.perm=700
HDFS-SITE.XML_dfs.http.policy=HTTPS_ONLY
HDFS-SITE.XML_dfs.web.authentication.kerberos.principal=HTTP/local@EXAMPLE.COM

# hdfs-site.xml ssl config
HDFS-SITE.XML_dfs.https.server.keystore.resource=ssl-server.xml
HDFS-SITE.XML_dfs.client.https.keystore.resource=ssl-client.xml

MAPRED-SITE.XML_mapreduce.framework.name=yarn
MAPRED-SITE.XML_yarn.app.mapreduce.am.env=HADOOP_MAPRED_HOME=$HADOOP_HOME
MAPRED-SITE.XML_mapreduce.map.env=HADOOP_MAPRED_HOME=$HADOOP_HOME
MAPRED-SITE.XML_mapreduce.reduce.env=HADOOP_MAPRED_HOME=$HADOOP_HOME

YARN-SITE.XML_yarn.resourcemanager.hostname=resourcemanager
YARN-SITE.XML_yarn.nodemanager.pmem-check-enabled=false
YARN-SITE.XML_yarn.nodemanager.delete.debug-delay-sec=600
YARN-SITE.XML_yarn.nodemanager.vmem-check-enabled=false
YARN-SITE.XML_yarn.nodemanager.aux-services=mapreduce_shuffle

CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.maximum-applications=10000
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.maximum-am-resource-percent=0.1
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.resource-calculator=org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.queues=default
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.capacity=100
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.user-limit-factor=1
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.maximum-capacity=100
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.state=RUNNING
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.acl_submit_applications=*
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.root.default.acl_administer_queue=*
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.node-locality-delay=40
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.queue-mappings=
CAPACITY-SCHEDULER.XML_yarn.scheduler.capacity.queue-mappings-override.enable=false

LOG4J.PROPERTIES_log4j.rootLogger=INFO, stdout
LOG4J.PROPERTIES_log4j.appender.stdout=org.apache.log4j.ConsoleAppender
LOG4J.PROPERTIES_log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
LOG4J.PROPERTIES_log4j.appender.stdout.layout.ConversionPattern=%d{yyyy-MM-dd HH:mm:ss} %-5p %c{1}:%L - %m%n
