<?xml version="1.0"?>
<configuration>
  <!-- Hive Metastore URI -->
  <property>
    <name>hive.metastore.uris</name>
    <value>thrift://hive-metastore:9083</value>
  </property>

  <!-- Warehouse Directory - Location of Hive data in HDFS -->
  <!-- <property>
    <name>hive.metastore.warehouse.dir</name>
    <value>hdfs://namenode:9000/user/hive/warehouse</value>
  </property>

  <property>
    <name>spark.sql.hive.metastore.version</name>
    <value>3.1.3</value>
  </property> -->

  <!-- <property>
    <name>spark.sql.hive.metastore.jars</name>
    <value>path/to/your/hive/metastore/jars or use "maven" to fetch automatically</value>
    <description>Location of Hive Metastore jars needed by Spark to interact with the Hive Metastore.</description>
  </property> -->

  <!-- JDBC Driver Class & Connection Details for Hive Metastore Database (if using remote metastore) -->
  <property>
    <name>javax.jdo.option.ConnectionDriverName</name>
    <value>org.postgresql.Driver</value>
  </property>
  
  <property>
    <name>javax.jdo.option.ConnectionURL</name>
    <value>jdbc:postgresql://postgres:5432/metastore_db</value>
  </property>
  
  <property>
    <name>javax.jdo.option.ConnectionUserName</name>
    <value>postgres</value>
  </property>
  
  <property>
    <name>javax.jdo.option.ConnectionPassword</name>
    <value>postgres</value>
  </property>
</configuration>